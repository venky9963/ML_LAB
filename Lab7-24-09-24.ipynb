{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c446e233-eded-47f7-87e7-46a79e88d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Perceptron Parameters: {'penalty': 'l1', 'max_iter': 2000, 'alpha': 0.001}\n",
      "Perceptron - Accuracy: 0.30666666666666664\n",
      "Perceptron - Precision: 0.7984675458530317\n",
      "Perceptron - Recall: 0.30666666666666664\n",
      "Perceptron - F1 Score: 0.278979159426382\n",
      "Best MLP Parameters: {'solver': 'adam', 'learning_rate': 'adaptive', 'hidden_layer_sizes': (100,), 'alpha': 0.001, 'activation': 'relu'}\n",
      "MLP - Accuracy: 0.7933333333333333\n",
      "MLP - Precision: 0.8252496639163307\n",
      "MLP - Recall: 0.7933333333333333\n",
      "MLP - F1 Score: 0.7938015746249985\n",
      "\n",
      "Comparison of Perceptron and MLP Classifier:\n",
      "           Model  Accuracy  Precision    Recall  F1 Score\n",
      "0     Perceptron  0.306667   0.798468  0.306667  0.278979\n",
      "1  MLPClassifier  0.793333   0.825250  0.793333  0.793802\n"
     ]
    }
   ],
   "source": [
    "#A2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the dataset (update the path as per your file location)\n",
    "data = pd.read_csv(\"C:/Users/Dell/Downloads/DCT_withoutduplicate 7.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(columns=['LABEL'])\n",
    "y = data['LABEL']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "### 1. Hyperparameter tuning for Perceptron\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Define hyperparameter search space for Perceptron\n",
    "param_dist_perceptron = {\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Regularization type\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],   # Strength of regularization\n",
    "    'max_iter': [1000, 2000, 3000]          # Maximum number of iterations\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV for Perceptron\n",
    "random_search_perceptron = RandomizedSearchCV(perceptron, param_distributions=param_dist_perceptron, \n",
    "                                              n_iter=10, scoring='accuracy', cv=5, random_state=42)\n",
    "random_search_perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best Perceptron model\n",
    "best_perceptron = random_search_perceptron.best_estimator_\n",
    "y_pred_perceptron = best_perceptron.predict(X_test)\n",
    "\n",
    "# Perceptron performance metrics\n",
    "perceptron_accuracy = accuracy_score(y_test, y_pred_perceptron)\n",
    "perceptron_precision = precision_score(y_test, y_pred_perceptron, average='weighted', zero_division=1)\n",
    "perceptron_recall = recall_score(y_test, y_pred_perceptron, average='weighted', zero_division=1)\n",
    "perceptron_f1 = f1_score(y_test, y_pred_perceptron, average='weighted', zero_division=1)\n",
    "\n",
    "print(\"Best Perceptron Parameters:\", random_search_perceptron.best_params_)\n",
    "print(\"Perceptron - Accuracy:\", perceptron_accuracy)\n",
    "print(\"Perceptron - Precision:\", perceptron_precision)\n",
    "print(\"Perceptron - Recall:\", perceptron_recall)\n",
    "print(\"Perceptron - F1 Score:\", perceptron_f1)\n",
    "\n",
    "### 2. Hyperparameter tuning for MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "# Define hyperparameter search space for MLP\n",
    "param_dist_mlp = {\n",
    "    'hidden_layer_sizes': [(50, 50), (100,), (50, 100)],  # Different hidden layer configurations\n",
    "    'activation': ['tanh', 'relu'],                       # Activation functions\n",
    "    'solver': ['adam', 'sgd'],                            # Optimizers\n",
    "    'alpha': [0.0001, 0.001, 0.01],                      # L2 regularization\n",
    "    'learning_rate': ['constant', 'adaptive']             # Learning rate schedule\n",
    "}\n",
    "\n",
    "# Setup RandomizedSearchCV for MLP\n",
    "random_search_mlp = RandomizedSearchCV(mlp, param_distributions=param_dist_mlp, \n",
    "                                       n_iter=10, scoring='accuracy', cv=5, random_state=42)\n",
    "random_search_mlp.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the best MLP model\n",
    "best_mlp = random_search_mlp.best_estimator_\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n",
    "\n",
    "# MLP performance metrics\n",
    "mlp_accuracy = accuracy_score(y_test, y_pred_mlp)\n",
    "mlp_precision = precision_score(y_test, y_pred_mlp, average='weighted', zero_division=1)\n",
    "mlp_recall = recall_score(y_test, y_pred_mlp, average='weighted', zero_division=1)\n",
    "mlp_f1 = f1_score(y_test, y_pred_mlp, average='weighted', zero_division=1)\n",
    "\n",
    "print(\"Best MLP Parameters:\", random_search_mlp.best_params_)\n",
    "print(\"MLP - Accuracy:\", mlp_accuracy)\n",
    "print(\"MLP - Precision:\", mlp_precision)\n",
    "print(\"MLP - Recall:\", mlp_recall)\n",
    "print(\"MLP - F1 Score:\", mlp_f1)\n",
    "\n",
    "### 3. Comparing results\n",
    "comparison_results = pd.DataFrame({\n",
    "    'Model': ['Perceptron', 'MLPClassifier'],\n",
    "    'Accuracy': [perceptron_accuracy, mlp_accuracy],\n",
    "    'Precision': [perceptron_precision, mlp_precision],\n",
    "    'Recall': [perceptron_recall, mlp_recall],\n",
    "    'F1 Score': [perceptron_f1, mlp_f1]\n",
    "})\n",
    "\n",
    "print(\"\\nComparison of Perceptron and MLP Classifier:\")\n",
    "print(comparison_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18cf94c4-fc00-4586-94f0-c51f492b0590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifier  Accuracy  Precision    Recall  F1-Score\n",
      "0            SVM  0.777778   0.833333  0.777778  0.738095\n",
      "1  Decision Tree  1.000000   1.000000  1.000000  1.000000\n",
      "2  Random Forest  1.000000   1.000000  1.000000  1.000000\n",
      "3       AdaBoost  1.000000   1.000000  1.000000  1.000000\n",
      "4        XGBoost  1.000000   1.000000  1.000000  1.000000\n",
      "5    Naive Bayes  0.944444   0.948718  0.944444  0.943030\n",
      "6       CatBoost  1.000000   1.000000  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load your dataset (replace with the correct file path)\n",
    "file_path = r'C:\\Users\\Dell\\Downloads\\DCT_withoutduplicate 7.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Filter the dataset to include only records with LABEL 3333 and 3334\n",
    "data_filtered = data[data['LABEL'].isin([3333, 3334])]\n",
    "\n",
    "# Map labels 3333 to 0 and 3334 to 1 using .loc\n",
    "data_filtered.loc[:, 'LABEL'] = data_filtered['LABEL'].map({3333: 0, 3334: 1})\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = data_filtered.drop('LABEL', axis=1)\n",
    "y = data_filtered['LABEL']\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a dictionary of classifiers to evaluate\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(algorithm='SAMME'),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True)  # Set silent=True to suppress output\n",
    "}\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # Store the results in the list\n",
    "    results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "\n",
    "# Convert the list of results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c51ac-7c7b-4b13-8a56-da7395ba9dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
